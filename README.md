
# ğŸ—ï¸ Bulldozer Sale Price Prediction using Machine Learning

This project builds a regression model to predict the sale prices of heavy machinery (specifically bulldozers) using historical auction data, enhanced with temporal features and categorical encoding strategies.

---

## ğŸ“Œ Project Overview

- **Objective**: Predict bulldozer sale prices using prior sales data.  
- **Problem Type**: Supervised Regression  
- **Domain**: Heavy Equipment / Auction Pricing Analytics  
- **Target Variable**: `SalePrice`  
- **Tech Stack**: Python, Jupyter Notebook, pandas, NumPy, matplotlib, seaborn, scikit-learn

---

## ğŸ“‚ Dataset Description

- **TrainAndValid.csv** â€“ ~412k rows, 53 columns including:
  - Identifier data (`SalesID`, `MachineID`, `ModelID`, `datasource`, `auctioneerID`)
  - Equipment features (`YearMade`, `UsageBand`, `ProductSize`, etc.)
  - `saledate` parsed as `datetime64`
  - Target field: `SalePrice`
- Includes a separate **Test.csv** for final predictions.

---

## ğŸ”„ Workflow

### 1. **Initial Data Exploration**
- Inspect data types and summary statistics
- Visualize sale price trends over time and by month
- Explore geographic variation using `state`

### 2. **Time-Series Feature Engineering**
- Convert `saledate` into:  
  `saleYear`, `saleMonth`, `saleDay`, `saleDayofweek`, `saleDayofyear`
- Remove the original `saledate` column

### 3. **Handling Missing Values & Encoding**
- **Numericals**: impute missing values with median + add `_is_missing` flag  
- **Categoricals**: convert to `category` type, and encode as integers (codes +1), retaining missing flags  
- Handle inconsistencies between train and test sets (e.g. ensuring `auctioneerID_is_missing` exists)

### 4. **Train-Validation Split**
- Investments from year 2012 as validation (~11k rows), and earlier years as training (~401k rows)

### 5. **Model Training & Evaluation**
- **Base Model**: RandomForestRegressor with `max_samples=10000`  
   â†’ Initial results:  
   - Trainingâ€¯MAE â‰ˆâ€¯5,550  
   - Validâ€¯MAE â‰ˆâ€¯7,097  
   - Validâ€¯RMSLE â‰ˆâ€¯0.2906  
   - Validâ€¯RÂ² â‰ˆâ€¯0.836  

- **Hyperparameter Tuning** using `RandomizedSearchCV` (20 candidates, 5â€‘fold CV)  
   â†’ Best tuning gave slightly worse validation performance (MAE â‰ˆ 7,568, RMSLE â‰ˆ 0.305)

- **Final â€œIdealâ€ Model** with selected hyperparameters:
  ```
  n_estimators=90, max_features=0.5, min_samples_split=14, min_samples_leaf=1, max_samples=None
  ```
  - Trainingâ€¯MAE â‰ˆ 2,930  
  - Validâ€¯MAE â‰ˆ 5,911  
  - Validâ€¯RMSLE â‰ˆ 0.2438  
  - Validâ€¯RÂ² â‰ˆ 0.884  

### 6. **Prediction on Test Set**
- Preprocess test data using same logic (adding missing flags, encoding categories)
- Align feature columns with training set
- Generate `SalePrice` predictions for submission with `SalesID`

### 7. **Feature Importance Interpretation**
- Displayed top 20 model features using a barplot  
- Confirmed that importance scores sum to 1.0

---

## ğŸ“ˆ Results Summary

| Model                 | Training MAE | Validation MAE | Valid RMSLE | Valid RÂ²  |
|-----------------------|--------------|----------------|-------------|-----------|
| Base Random Forest    | ~5,550        | ~7,097          | ~0.291      | ~0.836    |
| Tuned (RSâ€‘CV)         | ~6,050        | ~7,568          | ~0.305      | ~0.807    |
| Final â€œIdealâ€ Model   | ~2,930        | ~5,911          | ~0.244      | ~0.884    |

---

## ğŸ“ Requirements

Install the required Python libraries:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

---

## ğŸš€ How to Run

1. Clone or download the notebook and data (`TrainAndValid.csv`, `Test.csv`)
2. Install dependencies
3. Open and run the notebook in order:
   - Data loading & exploratory analysis
   - Feature engineering & preprocessing
   - Model training, evaluation & tuning
   - Generating predictions for test data

---

## ğŸ“ Suggested Project Structure

```
Bulldozer_Price_Prediction/
â”‚
â”œâ”€â”€ TrainAndValid.csv
â”œâ”€â”€ Test.csv
â”œâ”€â”€ Bulldozer_SalePrice_Prediction.ipynb  # Main notebook
â”œâ”€â”€ model/                                # (Optional) Saved trained model
â””â”€â”€ README.md
```

---

## âœ… Future Enhancements

- Optimize preprocessing (e.g. better imputation, outlier handling)
- Add feature selection or dimensionality reduction
- Try ensemble models (e.g., XGBoost, LightGBM) or stacking
- Use more sophisticated hyperparameter search (e.g. Bayesian optimization)
- Deploy interactive app via Streamlit or Flask
- Explore time-series crossâ€‘validation for temporally ordered data

---

## ğŸ‘¨â€ğŸ’» Author

**Deepak P.**  
Machine Learning Engineer | Predictive Analytics Enthusiast  
ğŸ“§ deepak@email.com | ğŸ”— LinkedIn | ğŸŒ Portfolio (optional)
